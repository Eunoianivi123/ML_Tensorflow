{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkq/8wRF7MHUYPpvgVFKr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eunoianivi123/ML_Tensorflow/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmrxydDAORHF"
      },
      "outputs": [],
      "source": [
        "#importing necessary packages\n",
        "from __future__ import division,unicode_literals,print_function,absolute_import\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#declaring the constants\n",
        "column_names =['SepalLength','SepalWidth','PetalLength','PetalWidth','Species']\n",
        "species_names=['Setosa','Versicolor','Veriginica']"
      ],
      "metadata": {
        "id": "u_vlD0d4UCft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using keras.utils to store the data in the fil named as iris_training.csv and iris_test.csv\n",
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\",\"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "#train and test are variables that contains the dataframe(consist of rows and columns). read_csv converts the csv file into dataframe\n",
        "train = pd.read_csv(train_path, names=column_names, header=0)\n",
        "test = pd.read_csv(test_path, names=column_names, header=0)\n"
      ],
      "metadata": {
        "id": "QJUJB0_fUi7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ3XHyKzfMbl",
        "outputId": "4fe6a0ed-347c-468d-8a01-47efd43802eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train.pop('Species')\n",
        "test_y = test.pop('Species')"
      ],
      "metadata": {
        "id": "DpFXvGVbH5so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data.Dataset converts it into objects and stores in dataset.If training is set to true, then it shuffles with the buffer size of 1000 and repreat indefinitely and returns the dataset with the batch size\n",
        "def input_fn(features,labels,training=True,batch_size = 256):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "  return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "BvHZrvzlJmqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_feature_columns=[]\n",
        "for key in train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "print(my_feature_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZBi8dNkNcRm",
        "outputId": "a2832db3-ed72-4084-837d-2058ac700be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-db882a998a6e>:3: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns = my_feature_columns,\n",
        "    hidden_units = [30,10],\n",
        "    n_classes = 3 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC7aCPPVN9bZ",
        "outputId": "7e06ff30-5f57-4862-bea1-bb6a75614ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/head/head_utils.py:59: MultiClassHead.__init__ (from tensorflow_estimator.python.estimator.head.multi_class_head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py:759: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1844: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2ddzmunx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "classifier.train(input_fn = lambda: input_fn(train,train_y,training=True),steps = 5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUXkBnMeQHsQ",
        "outputId": "5c58a716-fb3e-463d-b92b-7c46f9fa15c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1416: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1419: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1456: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7ed45d15dfc0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model\n",
        "eval_result = classifier.evaluate(input_fn= lambda: input_fn(test, test_y,training = False))\n",
        "print('\\n Test set accuracy : {accuracy:0.3f}\\n'. format(**eval_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpg0pNG3SaDN",
        "outputId": "4188b44c-288a-44bd-e41a-34b015e9ddc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test set accuracy : 0.900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making the predictions\n",
        "def input_fn(features, batch_size= 256):\n",
        "  return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength','PetalWidth']\n",
        "predict_input = {}\n",
        "\n",
        "for feature in  features:\n",
        "  valid = True\n",
        "  while valid:\n",
        "    val = input(feature + \": \")\n",
        "    if not val.isdigit(): valid = False\n",
        "\n",
        "  predict_input[feature] = [float(val)]\n",
        "\n",
        "predictions = classifier.predict(input_fn = lambda: input_fn(predict_input))\n",
        "for pred_dict in predictions:\n",
        "  class_id = pred_dict['class_ids'][0]\n",
        "  probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "print('Prediction is \"{}\" ({:.1f}%)'.format(species_names[class_id],100 * probability))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt2WIhtaYPrk",
        "outputId": "2c29c0ad-bafd-4628-9d63-17c129a8154f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SepalLength: 1.1\n",
            "SepalWidth: 2.1\n",
            "PetalLength: 3.1\n",
            "PetalWidth: 4.1\n",
            "<generator object Estimator.predict at 0x7ed45d1c0970>\n",
            "Prediction is \"Setosa\" (41.8%)\n"
          ]
        }
      ]
    }
  ]
}